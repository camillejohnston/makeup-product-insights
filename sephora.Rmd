---
title: "Trends in Sephora Reviews"
author: "Camille Johnston"
date: "Last compiled on `r format(Sys.time(), '%d %B, %Y')`"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Load packages

```{r}
library(tidyverse) ## Always load tidyverse
library(tidytext) ## Needed for text analysis
library(data.table) ## Faster reading and writing of large files 
library(plotly) ## Interactive plots
```


# Load data

```{r}
# List CSV files, read them, and rbind into a single data frame
sephora <- list.files(path = "/Users/camillejohnston/Documents/TidyTuesday/sephora_101423/", 
                            pattern = "^reviews.*\\.csv$", 
                            full.names = TRUE) %>%
  map_df(~ fread(.x), .id = "file_id") %>% 
  select(product_id, product_name, brand_name, submission_time, rating, is_recommended, review_title, review_text) %>% 
  mutate(year = as.numeric(substr(submission_time, 1, 4))) %>%
  distinct()

sum(duplicated(sephora))
```


# Explore 

```{r}
range(sephora$submission_time)

skimr::skim(sephora)
```


# Unnest tokens

```{r}
sephora_tokens <- sephora %>%
  unite("review_title_and_test", review_title, review_text, sep = " ") %>%
  unnest_tokens(word, review_title_and_test)
```


# Counting tokens

```{r}
sephora_token_counts <- sephora_tokens %>%
  group_by(word) %>% 
  summarise(n = n(),
            average_rating = mean(rating, na.rm=TRUE), 
            average_recommendation = mean(is_recommended, na.rm=TRUE)) %>%
  arrange(-n) %>% 
  filter(n>150) ## we have about 15 years of data, this filters down words used more than ~10x per year

skimr::skim(sephora_token_counts)
summary(sephora_token_counts$n)

sephora_token_counts %>% 
  ggplot(aes(n)) + 
  geom_histogram(color="black", fill="lightsteelblue1") + 
  geom_vline(aes(xintercept = mean(n, na.rm=TRUE))) +
  scale_x_log10()
```


# Which words are associated with higher or lower ratings?

```{r}
sephora_token_counts %>%
  anti_join(get_stopwords()) %>%
  ggplot(aes(n, average_rating)) +
  geom_hline(yintercept = 2.63, lty = 2, color = "grey", size = 0.5) +
  geom_text(aes(label = word), check_overlap = TRUE, show.legend = FALSE, vjust = "top", hjust = "left") +
  scale_x_log10() +  ## Use a logarithmic scale for the x-axis
  #xlim(140, 300)+
  theme_classic()  ## Use a classic theme for the plot

```


# Grouping word use by year

```{r}
setDT(sephora_tokens)

# Assuming your data is in a data.table named your_data_table
sephora_token_counts_grouped <- sephora_tokens[, .(n = .N, average_rating = mean(rating, na.rm = TRUE), average_recommendation = mean(is_recommended, na.rm = TRUE)), by = .(word, year)]

sephora_token_counts_grouped <- as.data.frame(sephora_token_counts_grouped)

# sephora_token_counts_year <- sephora_tokens[n > 10]
# sephora_token_counts_year <- sephora_token_counts_year[.N > 8]

sephora_token_counts_year <- sephora_token_counts_grouped %>% 
  arrange(-n)%>% 
  filter(n>10) %>% ## we have about 15 years of data, this filters down words used more than ~10x per year
  group_by(word) %>%
  filter(n() > 8) %>% ## keep words that had substanial use more than half of the years
  ungroup()


sephora_token_counts_year <- sephora_tokens %>%
  group_by(word, year) %>% 
  summarise(n = n(),
            average_rating = mean(rating, na.rm=TRUE), 
            average_recommendation = mean(is_recommended, na.rm=TRUE)) %>%
  arrange(-n)%>% 
  filter(n>10) %>% ## we have about 15 years of data, this filters down words used more than ~10x per year
  group_by(word) %>%
  filter(n() > 8) %>% ## keep words that had substantial use more than half of the years
  ungroup()

skimr::skim(sephora_token_counts_year)
summary(sephora_token_counts_year$n)
table(sephora_token_counts_year$year)

sephora_token_counts_year %>% 
  ggplot(aes(n)) + 
  geom_histogram(color="black", fill="lightsteelblue1") + 
  geom_vline(aes(xintercept = mean(n, na.rm=TRUE))) +
  scale_x_log10()
```


# Exploring word use trajectories across year

```{r}
sephora_token_counts_year %>% 
  ggplot(aes(x = year, y = average_rating, group = word, color = n)) +
  geom_line() +
  labs(x = "Year", y = "Score") +
  theme_minimal()

sephora_token_counts_year %>% 
  ggplot(aes(x = year, y = average_rating, group = word)) +
  geom_smooth(method = "lm", se = FALSE) +  # Fit linear regression lines
  labs(x = "Year", y = "Score") +
  theme_minimal()
```


# Fitting relationship between word use over time and product rating

```{r}
linear_slopes <- sephora_token_counts_year %>%
  group_by(word) %>%
  do(model = lm(average_rating ~ year, data = .)) %>%
  summarize(
    word = word[1], 
    slope = coef(model)[2],         # Extract the slope coefficient
    intercept = coef(model)[1],     # Extract the intercept coefficient
    significance = summary(model)$coefficients[2, 4]  # Extract the p-value for the slope
  ) %>%
  ungroup()
```


# Which words have most substantial change in associated rating over time?

```{r}
linear_slopes %>% 
  filter(significance < 0.05) %>% 
  slice_max(abs(slope), n = 50) %>%
  ungroup() %>%
  ggplot(aes(slope, fct_reorder(word, slope), fill = slope > 0)) +
  geom_col(alpha = 0.8) +
  theme_classic()
```


# Plotting words with substantial change in associated rating over time

```{r}
linear_slopes_significant <-  linear_slopes %>% 
  filter(significance < 0.01)

linear_slopes_significant_words <- linear_slopes_significant %>% 
  filter(abs(slope) >= 0.1) %>% 
  select(word)
  
token_trajectories_lm <- sephora_token_counts_year %>% 
  right_join(linear_slopes_significant_words) %>% 
  ggplot(aes(x = year, y = average_rating, group = word, color = word)) +
  geom_smooth(method = "lm", se = FALSE) +  
  labs(x = "Year", y = "Score") +
  theme_classic()

token_trajectories_loess <- sephora_token_counts_year %>% 
  right_join(linear_slopes_significant_words) %>% 
  ggplot(aes(x = year, y = average_rating, group = word, color = word)) +
  geom_smooth(method = "loess", se = FALSE) +  # Fit loess lines
  labs(x = "Year", y = "Score") +
  theme_classic() 

ggplotly(token_trajectories_lm)
ggplotly(token_trajectories_loess)
```


# Save data 

```{r}
fwrite(sephora_tokens, "/Users/camillejohnston/Documents/TidyTuesday/sephora_101423/processed_data/sephora_tokens.csv")
fwrite(sephora_token_counts, "/Users/camillejohnston/Documents/TidyTuesday/sephora_101423/processed_data/sephora_token_counts.csv")
fwrite(sephora_token_counts_year, "/Users/camillejohnston/Documents/TidyTuesday/sephora_101423/processed_data/sephora_token_counts_year.csv")
fwrite(linear_slopes, "/Users/camillejohnston/Documents/TidyTuesday/sephora_101423/processed_data/linear_slopes.csv")
```


# Read back in processed data if needed

```{r}
sephora_tokens <- fread("/Users/camillejohnston/Documents/TidyTuesday/sephora_101423/processed_data/sephora_tokens.csv")
sephora_token_counts <- fread("/Users/camillejohnston/Documents/TidyTuesday/sephora_101423/processed_data/sephora_token_counts.csv")
sephora_token_counts_year <- fread("/Users/camillejohnston/Documents/TidyTuesday/sephora_101423/processed_data/sephora_token_counts_year.csv")
linear_slopes <- fread("/Users/camillejohnston/Documents/TidyTuesday/sephora_101423/processed_data/linear_slopes.csv")
```

